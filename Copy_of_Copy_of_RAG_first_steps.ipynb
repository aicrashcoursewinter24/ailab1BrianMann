{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aicrashcoursewinter24/ailab1BrianMann/blob/lab6/Copy_of_Copy_of_RAG_first_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD_GcamIl8vW",
        "outputId": "a2126158-5a46-4e49-e74c-3118e5655676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (2.8.8)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.14)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (4.2)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from numexpr) (1.23.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.13 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: lxml>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (4.9.4)\n",
            "Requirement already satisfied: curl-cffi>=0.5.10 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.5.10)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.60.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.60.0)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.0.7)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.10.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.1.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6.1)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.15.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from curl-cffi>=0.5.10->duckduckgo-search) (1.16.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12.0->curl-cffi>=0.5.10->duckduckgo-search) (2.21)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx<1,>=0.23.0->openai) (4.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install numexpr openai langchain_openai langchain langchain-community duckduckgo-search loguru qdrant-client sentence-transformers tiktoken docx2txt unstructured tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders.base import BaseLoader\n",
        "from langchain_core.embeddings import Embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "\n",
        "def parse_xml_to_dict(file_path: str) -> Dict[str, Any]:\n",
        "    # Parse the XML file\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Function to parse each review element\n",
        "    def parse_review(review_element: ET.Element) -> Dict[str, Any]:\n",
        "        review_data = {}\n",
        "        for child in review_element:\n",
        "            if child.tag == 'reviewer':\n",
        "                # Special handling for nested 'reviewer' tag\n",
        "                reviewer_data = {grandchild.tag: grandchild.text for grandchild in child}\n",
        "                review_data[child.tag] = reviewer_data\n",
        "            else:\n",
        "                review_data[child.tag] = child.text\n",
        "        return review_data\n",
        "\n",
        "    # Parse all reviews\n",
        "    reviews = [parse_review(review) for review in root]\n",
        "    return reviews\n",
        "\n",
        "\n",
        "class XMLReviewLoader(BaseLoader):\n",
        "    def __init__(self, file_path: str):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def load(self) -> List[Document]:\n",
        "        docs = parse_xml_to_dict(self.file_path)\n",
        "        return [Document(page_content=json.dumps(doc)) for doc in docs]\n",
        "\n",
        "\n",
        "class VerboseEmbeddings(Embeddings):\n",
        "    def __init__(self, embeddings: Embeddings):\n",
        "        self.embeddings = embeddings\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        print(f\"Embedding {len(texts)} documents\")\n",
        "        return self.embeddings.embed_documents(texts)\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        print(f\"Embedding query: {text}\")\n",
        "        return self.embeddings.embed_query(text)\n",
        "\n",
        "\n",
        "def build_vectorstore_from_xml_directory(path: str, vectorstore_path: str, loading_glob=\"**/*.xml\",\n",
        "                                         collection_name=\"my_documents\",\n",
        "                                         embeddings: Embeddings = VerboseEmbeddings(HuggingFaceEmbeddings())):\n",
        "    # setting up a document loader which loads all xml reviews in the directory\n",
        "    dir_loader = DirectoryLoader(path=path, glob=loading_glob, loader_cls=XMLReviewLoader,\n",
        "                                 show_progress=True, use_multithreading=True)\n",
        "    docs = dir_loader.load()\n",
        "    # splitting the xml documents into chunks of 1000 characters with an overlap of 200 characters\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=3000, chunk_overlap=100, add_start_index=True\n",
        "    )\n",
        "    all_splits: List[Document] = text_splitter.split_documents(docs)\n",
        "    print(f\"Split {len(docs)} documents into {len(all_splits)} chunks\")\n",
        "    # setting up a vectorstore with the Qdrant backend\n",
        "    vectorstore = Qdrant.from_documents(\n",
        "        all_splits,\n",
        "        embeddings,\n",
        "        path=vectorstore_path,\n",
        "        collection_name=collection_name\n",
        "    )\n",
        "    # search args could return a different number of nearest neighbors.  Arbitrarily putting \"6\" here.\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "    return retriever\n",
        "\n",
        "\n",
        "def retriever_tool(retriever):\n",
        "    \"\"\"Creates a tool that searches the vectorstore for documents similar to the input text.\"\"\"\n",
        "    tool = create_retriever_tool(\n",
        "        retriever,\n",
        "        \"search_xml_documents\",\n",
        "        \"Searches inside of our local store old Best Buy reviews.  \" +\n",
        "        \"Useful for understanding how people talk about products from the early 2010's era\",\n",
        "    )\n",
        "    return tool\n",
        "\n"
      ],
      "metadata": {
        "id": "2zPgYmkUmbBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrDcfmq5m7Bu",
        "outputId": "a702c03d-c4d1-4c49-c147-6a805d26da2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/product_reviews"
      ],
      "metadata": {
        "id": "mlqN_ZhooAva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00eedbf-0cc8-4ec9-afaf-8d81d180a0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reviews_0001_24122_to_98772.xml      reviews_0024_5130266_to_5247642.xml\n",
            "reviews_0002_98780_to_345240.xml     reviews_0025_5247643_to_5363104.xml\n",
            "reviews_0003_345248_to_501823.xml    reviews_0026_5363109_to_5806838.xml\n",
            "reviews_0004_501835_to_691133.xml    reviews_0027_5806868_to_6022633.xml\n",
            "reviews_0005_691144_to_831905.xml    reviews_0028_6022641_to_6172272.xml\n",
            "reviews_0006_831928_to_1117787.xml   reviews_0029_6172275_to_6358111.xml\n",
            "reviews_0007_1117796_to_1382936.xml  reviews_0030_6358125_to_6396149.xml\n",
            "reviews_0008_1382981_to_1597862.xml  reviews_0031_6396154_to_6423017.xml\n",
            "reviews_0009_1597878_to_1906168.xml  reviews_0032_6423025_to_6486864.xml\n",
            "reviews_0010_1906234_to_2063675.xml  reviews_0033_6486865_to_6587831.xml\n",
            "reviews_0011_2063679_to_2151936.xml  reviews_0034_6587839_to_6701463.xml\n",
            "reviews_0012_2151940_to_2284992.xml  reviews_0035_6701490_to_6801194.xml\n",
            "reviews_0013_2285000_to_2440628.xml  reviews_0036_6801200_to_6889357.xml\n",
            "reviews_0014_2440655_to_2799035.xml  reviews_0037_6889364_to_6950068.xml\n",
            "reviews_0015_2799189_to_3197154.xml  reviews_0038_6950072_to_7039369.xml\n",
            "reviews_0016_3197161_to_3395314.xml  reviews_0039_7039382_to_7198559.xml\n",
            "reviews_0017_3395388_to_4017768.xml  reviews_0040_7198571_to_7269645.xml\n",
            "reviews_0018_4017769_to_4160192.xml  reviews_0041_7269649_to_7387421.xml\n",
            "reviews_0019_4160194_to_4209454.xml  reviews_0042_7387427_to_7479780.xml\n",
            "reviews_0020_4209473_to_4286992.xml  reviews_0043_7479787_to_7610126.xml\n",
            "reviews_0021_4286995_to_4472320.xml  reviews_0044_7610127_to_7736345.xml\n",
            "reviews_0022_4472324_to_4833387.xml  reviews_0045_7736346_to_7762248.xml\n",
            "reviews_0023_4833425_to_5130263.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "review_dir = \"drive/MyDrive/product_reviews\"\n"
      ],
      "metadata": {
        "id": "lN7nUxYHmkSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = build_vectorstore_from_xml_directory(collection_name=\"test\", path=review_dir, loading_glob=\"**/reviews_0001_24122_to_98772.xml\", vectorstore_path='/content/reviews')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_O2ZHH7nq9n",
        "outputId": "27ee08bc-8404-4d6a-c67b-646f7dd39ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 5000 documents into 5024 chunks\n",
            "Embedding 1 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 64 documents\n",
            "Embedding 32 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_tool = retriever_tool(retriever)"
      ],
      "metadata": {
        "id": "jpsiTF94o7s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from langchain.agents import AgentExecutor, AgentType, load_tools, initialize_agent\n",
        "from langchain.chat_models import ChatAnyscale\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "c3Z558qHpmDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "llm = ChatAnyscale(anyscale_api_base=\"https://api.endpoints.anyscale.com/v1\",\n",
        "                   anyscale_api_key=userdata.get(\"ANYSCALE_API_KEY\"),\n",
        "                   model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "                   temperature=0.7,\n",
        "                   verbose=True)"
      ],
      "metadata": {
        "id": "UAS-THoIpq28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\", \"ddg-search\"], llm=llm) + [review_tool]"
      ],
      "metadata": {
        "id": "-CKcIRV5p8d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "print(agent.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvOtjxmYp_Wv",
        "outputId": "a3fa950a-4068-425b-e0ee-4079b240903e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "duckduckgo_search: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "search_xml_documents: Searches inside of our local store old Best Buy reviews.  Useful for understanding how people talk about products from the early 2010's era\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Calculator, duckduckgo_search, search_xml_documents]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What were the best iphone accessories to buy in 2011 or so?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He_GewBeqGQS",
        "outputId": "9a71e243-c7a5-46f0-adcc-a1fb9ab7047d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to look for the best iPhone accessories that were popular around 2011. I can use the `search_xml_documents` tool to search through old Best Buy reviews from that time period.\n",
            "\n",
            "Action: search_xml_documents\n",
            "Action Input: \"iPhone accessories 2011\"\n",
            "Observation\u001b[0mEmbedding query: iPhone accessories 2011\"\n",
            "Observation\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m[Document(page_content='{\"id\": \"69709\", \"sku\": \"8464084\", \"reviewer\": {\"name\": \"Polo\"}, \"aboutMe\": null, \"rating\": \"5.0\", \"title\": \"Very Well-Designed\", \"comment\": \"I had to get a velcro replacement for my Blackberry 7290 because the hard case that came with it was terrible. I am very active - chosing to run up three flights of stairs instead of taking the elevator. The phone kept falling out whenever I bent over or barely bumped it. When I got my new Blackberry 8830, I went ahead and got this new leather case with the very convenient magnetic flap. It\\'s great! My new Blackberry never falls out! Getting my BB in and out of the case is a snap! No loud velcro ripping noises - nice and quiet! The magnetic flap \\\\\"pops\\\\\" into place without sticking to my clothes.\", \"submissionTime\": \"2007-09-17T06:40:42\"}', metadata={'start_index': 0}), Document(page_content='{\"id\": \"70166\", \"sku\": \"8464084\", \"reviewer\": {\"name\": \"NearEasley\"}, \"aboutMe\": null, \"rating\": \"4.0\", \"title\": \"Best phone case I\\'ve found\", \"comment\": \"The convenience of the magnet snap is great for removal and replacing the phone. I like this much better than the belt clip case I had for my previous phone. Phone rotates to a horizonal position or vertical for comfort. Holder is well worth the price to protect your phone.\", \"submissionTime\": \"2007-09-17T10:39:51\"}', metadata={'start_index': 0}), Document(page_content='{\"id\": \"68026\", \"sku\": \"5335657\", \"reviewer\": {\"name\": \"ryancn77\"}, \"aboutMe\": null, \"rating\": \"5.0\", \"title\": \"most comfertable ever\", \"comment\": \"iv had mine for over 6 monthes now, there stury like the reaguler loop around the ear headphones but dont hurt your ears at all and the acteral phone is in the ear so you get exilent sound also the cord is verry strong ,ive pulled on the cords really hard qite a few times bye acedent but the inner cord never fails.\", \"submissionTime\": \"2007-09-16T02:50:45\"}', metadata={'start_index': 0}), Document(page_content='{\"id\": \"60700\", \"sku\": \"7184619\", \"reviewer\": {\"name\": \"Bargainhunter\"}, \"aboutMe\": null, \"rating\": \"5.0\", \"title\": \"The price is right\", \"comment\": \"I bought this case with my rewardzone points so it was basically free but i would gladly pay 9.99 for it because it is compact but has extra pockets for a memory card and shoulder strap.\", \"submissionTime\": \"2007-09-12T08:54:13\"}', metadata={'start_index': 0}), Document(page_content='{\"id\": \"78286\", \"sku\": \"8509438\", \"reviewer\": {\"name\": \"musicisme\"}, \"aboutMe\": null, \"rating\": \"5.0\", \"title\": \"satisfying\", \"comment\": \"This product is a good companion with the ipod.It has the best sound,no complaints about it.It has a wide range remote.As long as you have some good songs on it,you can powerhouse it for your listening enjoyments.Say your traveling in an RV,instead of watching the terrain change from now and then,apply your ipod to the dock to listen to your favorite songs along with your family and friends.The black color gives it a sleek good finish.BOSE is a good company,they sell earphones and high standard electronics,and not to mention,the sound dock for the ipod.I\\'d say this item is a must for travelers.\", \"submissionTime\": \"2007-09-22T08:00:05\"}', metadata={'start_index': 0}), Document(page_content='{\"id\": \"67396\", \"sku\": \"8033629\", \"reviewer\": {\"name\": \"aju12\"}, \"aboutMe\": null, \"rating\": \"4.0\", \"title\": \"Awesome...if you have a Nano\", \"comment\": \"I got this thinking it could work with my iPod video, but it didn\\'t. Fourtunately, my brother lets me borrow his iPod Nano for when I run so I can still get some use out of it. And when I do use it, it works great!\", \"submissionTime\": \"2007-09-15T17:27:38\"}', metadata={'start_index': 0})]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The search results don't provide a list of the best iPhone accessories from 2011. However, I can use this data to understand how people talked about products during that time. The reviews are for various products like phone cases, headphones, and an iPod dock. Since the question is about iPhone accessories, the relevant reviews are for a phone case and headphones. The user \"ryancn77\" mentioned their headphones as being comfortable and having good sound quality. User \"Bargainhunter\" praised a phone case for its compact size and additional pockets. Given that I couldn't find a direct answer in these reviews, I can search the web to find a list of the best iPhone accessories from 2011.\n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: \"best iPhone accessories 2011\"\n",
            "Observation\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mApple Apple MagSafe Charger There are often better and cheaper alternatives to Apple's first-party accessories, but the company's MagSafe wireless charger is worth considering if you have a new... 1 Best iPhone Case OtterBox SYMMETRY SERIES+ MagSafe Case $30 at Amazon Credit: Brandon Carte This Otterbox Magsafe case walks that fine line between toughness and slimness to better protect your iPhone without making it feel like you're lugging a brick around. ZDNET Regularly researches and tests the best Apple and Apple compatible products on the market, and compiled this list with the best accessories you can buy for your iPhone, with... 1. Apple AirPods Pro (second generation) Best Wireless Earbuds for iPhone AirPods Pro Enjoy Apple's H2 chip and experience better noise cancellation, crisp audio, and ruch bass. Including four... Apple FineWoven Case — $59 (Image credit: Future) The FineWoven case took something of a beating when it first came out alongside the iPhone 15 series. Easy to see why; the material isn't as...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The web search provides some recommendations for the best iPhone accessories from 2011, including the Apple MagSafe Charger, a specific iPhone case by OtterBox, and Apple's AirPods Pro. However, the search results mostly contain modern accessories, and I couldn't find any definitive list specific to 2011. I can still mention these recommended accessories and provide a disclaimer that the list might not be exclusively from 2011.\n",
            "\n",
            "Final Answer: In 2011, some of the well-regarded iPhone accessories included the Apple MagSafe Charger, a protective case from OtterBox, and Apple's AirPods Pro (although the Pro model was released much later). Please note that this information is based on modern search results, and I couldn't find a definitive list specific to 2011.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What were the best iphone accessories to buy in 2011 or so?',\n",
              " 'output': \"In 2011, some of the well-regarded iPhone accessories included the Apple MagSafe Charger, a protective case from OtterBox, and Apple's AirPods Pro (although the Pro model was released much later). Please note that this information is based on modern search results, and I couldn't find a definitive list specific to 2011.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke(\"What is the hardest color for the human eye to see?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4wRMA9yg_2o",
        "outputId": "b6929f8e-34cf-4a64-8791-8092f8da0d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I don't have the ability to perceive things directly, so I need to rely on external sources to answer this question. I will use the duckduckgo_search tool to find more information.\n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: hardest color for the human eye to see\n",
            "Observation\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mIn this blog post, we'll delve into the fascinating topic of the hardest color for humans to see. From the rarity of colors to the limitations of our eyes, we'll explore why certain hues, particularly purple, are considered more difficult for the human eye to perceive. We'll also debunk common misconceptions about colors like black and ... We can reach into such impossible colors a little by fatiguing i.e. red and blue cones and then looking at a pure green light. On a final note, screens are horrible at making fully saturated colors. It's probably healthy to buy a physical color atlas and look though it from time to time. - Kevin Kostlan Nov 1, 2023 at 18:19 2 It is a rare color in plants and animals, and fewer species have blue attributes compared to other colors. What color is the hardest to see at night? The color that is hardest to see at night is Red. The cones in our eyes, responsible for color vision, are less sensitive to red light in low-light conditions, making it difficult to distinguish ... Environmental Factors: Weather conditions like fog, rain, or snow can affect visibility in night vision cameras. These factors can reduce the clarity of images and make it harder to distinguish colors. Contrast: The contrast between the object and its surroundings also plays a role in visibility. 61 votes Ultraviolet Ultraviolet light, also known as blacklight, is outside the range of human vision and can only be detected with specialized equipment. Learn more 2 35 votes Infrared Infrared light is also outside the range of human vision and can only be detected with specialized equipment. Learn more 3 13 votes Dark blue\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The information I found suggests that purple is considered the hardest color for humans to see, and it's also a rare color in plants and animals. However, when it comes to night vision, red is the most difficult color for humans to discern. I will include both pieces of information in my final answer.\n",
            "\n",
            "Final Answer: The hardest color for the human eye to see is generally considered to be purple due to its rarity in nature. However, if we focus on night vision, red becomes the most challenging color for the human eye to distinguish.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the hardest color for the human eye to see?',\n",
              " 'output': 'The hardest color for the human eye to see is generally considered to be purple due to its rarity in nature. However, if we focus on night vision, red becomes the most challenging color for the human eye to distinguish.'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I added a new invoke statement. I think it is cool how it tries to come across as humman during its information retrieval process."
      ],
      "metadata": {
        "id": "3vJptglohQAr"
      }
    }
  ]
}